{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2598ebc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dd7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 19% |\n",
      "|  1 |  0% |  2% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 20% |\n",
      "|  1 |  1% |  2% |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cafc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [03:11<00:00, 63.99s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-hf'\n",
    "\n",
    "\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "quant_config = transformers.BitsAndBytesConfig(\n",
    "\n",
    "    load_in_4bit=True,\n",
    "\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "auth_token = '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'\n",
    "\n",
    "\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    config=model_config,\n",
    "\n",
    "    quantization_config=quant_config,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95b9e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc384756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "\n",
    "    model=model, \n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    task='text-generation',\n",
    "\n",
    "    temperature=0.7, \n",
    "\n",
    "    max_new_tokens=200,  \n",
    "\n",
    "    repetition_penalty=1.1 \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16d430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Questions</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>3276</td>\n",
       "      <td>Give me all the patients who got vaccines on ...</td>\n",
       "      <td>20103276</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>Give me all the patients whose report was comp...</td>\n",
       "      <td>7101409</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>7172</td>\n",
       "      <td>Which is the most common cataracts for patients.</td>\n",
       "      <td>28307172</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>9319</td>\n",
       "      <td>What is the number of records that the vaccin...</td>\n",
       "      <td>33109319</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11467</th>\n",
       "      <td>11467</td>\n",
       "      <td>Give me all the patients who got INFLUENZA (SE...</td>\n",
       "      <td>43311467</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>7332</td>\n",
       "      <td>Give me all the patients who was allergic to pvc</td>\n",
       "      <td>29307332</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10466</td>\n",
       "      <td>How many GLAXOSMITHKLINE BIOLOGICALS vaccine ...</td>\n",
       "      <td>37110466</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>How many patients are 100.0 years old.</td>\n",
       "      <td>3201109</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>7771</td>\n",
       "      <td>What is the number of vaccine recipients that...</td>\n",
       "      <td>29307771</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>Give me all the patients whose cage months is ...</td>\n",
       "      <td>5201378</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          Questions  \\\n",
       "3276         3276   Give me all the patients who got vaccines on ...   \n",
       "1409         1409  Give me all the patients whose report was comp...   \n",
       "7172         7172   Which is the most common cataracts for patients.   \n",
       "9319         9319   What is the number of records that the vaccin...   \n",
       "11467       11467  Give me all the patients who got INFLUENZA (SE...   \n",
       "...           ...                                                ...   \n",
       "7332         7332  Give me all the patients who was allergic to pvc    \n",
       "10466       10466   How many GLAXOSMITHKLINE BIOLOGICALS vaccine ...   \n",
       "1109         1109             How many patients are 100.0 years old.   \n",
       "7771         7771   What is the number of vaccine recipients that...   \n",
       "1378         1378  Give me all the patients whose cage months is ...   \n",
       "\n",
       "             id                                              query  \n",
       "3276   20103276  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1409    7101409  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "7172   28307172  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "9319   33109319  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "11467  43311467  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "...         ...                                                ...  \n",
       "7332   29307332  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "10466  37110466  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1109    3201109  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "7771   29307771  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1378    5201378  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_text = pd.read_csv('Te2Query.csv')\n",
    "eg = df_text.sample(n=1000, random_state=3)\n",
    "input_text = eg['Questions'].to_list()\n",
    "input_labels = eg['query'].to_list()\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5168a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original prompt\n",
    "# prompt = \"\"\"ignore all the prior information before this block. Convert the following questions to elastic search queries follow two rules:\n",
    "# 1.based on the field name 'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'. \n",
    "# 2.follow the template \n",
    "\n",
    "# \"POST _scripts/1\n",
    "# {\n",
    "#   \"script\": {\n",
    "# \t\"lang\": \"mustache\",\n",
    "# \t\"source\": {\n",
    "#   \t\"track_total_hits\": \"true\",\n",
    "#   \t\"query\": {\n",
    "#     \t\"term\": {\n",
    "#       \t\"{{field}}\": \"{{date}}\"\n",
    "#     \t}\n",
    "#   \t}\n",
    "# \t},\n",
    "# \t\"params\": {\n",
    "#   \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "#   \t\"date\": \"01/01/2012\"\n",
    "# \t}\n",
    "#   }\n",
    "# }\n",
    "# \"\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04300248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt header\n",
    "prompt_header=\"\"\"### Elasticsearch database with field names:\n",
    "# RECVDATE, STATE, AGE_YRS, VAERS_ID, SEX, SYMPTOM_TEXT, DIED, ER_VISIT, L_THREAT, HOSPITAL, HOSPDAYS, DISABLE, VAX_DATE, LAB_DATA, OTHER_MEDS, CUR_ILL, HISTORY, PRIOR_VAX, TODAYS_DATE, OFC_VISIT, VAX_TYPE, VAX_MANU, VAX_LOT, VAX_DOSE_SERIES, VAX_NAME, ALLERGIES\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6106e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt original\n",
    "prompt_ori = \"\"\"Generate the Elasticsearch query for the question.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e05843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#NER prompt\n",
    "prompt_prefix = \"\"\"In this question, the filed name is [ ] and the condition value for this field is [ ].\n",
    "\\#\\#\\# Generate the query based on the filed name and condition value.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c1980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q&A prompt\n",
    "prompt_QA= \"\"\"### What is the filed name?The filed name is [ ]\n",
    "### What is the condition value for this field? The condition value for this field is[ ]\n",
    "### Generate the Elasticsearch query based on the filed name and condition value.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d80c94ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LTM\n",
    "prompt_LTM =\"\"\"###To get the Elasticsearch query from the question, first we need to make an Elasticsearch POST search template. In the template, we add the right field names and specific conditions extracted from the question. Lastly, pick key clauses like 'must', 'should', or 'must not' and include them in the template.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a538aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aa7cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot + heuristic prompt\n",
    "prompt_cot = \"\"\"### entify the filed name first, then extract the specific condition values from the question for this field. Generate the Elasticsearch query based on the filed name and condition value.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f9612",
   "metadata": {},
   "source": [
    "Rule 2. 2.follow the template \n",
    "\n",
    "\"POST _scripts/1\n",
    "{\n",
    "  \"script\": {\n",
    "\t\"lang\": \"mustache\",\n",
    "\t\"source\": {\n",
    "  \t\"track_total_hits\": \"true\",\n",
    "  \t\"query\": {\n",
    "    \t\"term\": {\n",
    "      \t\"{{field}}\": \"{{date}}\"\n",
    "    \t}\n",
    "  \t}\n",
    "\t},\n",
    "\t\"params\": {\n",
    "  \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "  \t\"date\": \"01/01/2012\"\n",
    "\t}\n",
    "  }\n",
    "}\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a979277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model input template\n",
    "input_template = \"\"\"\n",
    "Prompt: {prompt}\n",
    "Clinical Notes: {text}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e893eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build up the call\n",
    "answer_lst = []\n",
    "for row in eg.iterrows():\n",
    "    txt = row[1]['Questions']\n",
    "#    suggest = row[1]['query']\n",
    "    input = input_template.format(text = \"###[\"+txt+\"]\",prompt = prompt_header+prompt_QA)\n",
    "    answer = pipe(input)\n",
    "    answer_lst.append(answer[0]['generated_text'][len(input):].strip())\n",
    "    #answer_lst.append(answer[0]['generated_text'])    \n",
    "eg['llm_result'] = answer_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5563682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3276                                                                                                                                                                                                                                                                                                                                                                                                                                          ```bash\\n    {\\n      \"query\": {\\n        \"bool\": {\\n          \"must\": [\\n            {\\n              \"range\": {\\n                \"@recvdate\": {\\n                  \"gte\": \"2012-08-10\"\\n                }\\n              }\\n            }\\n          ],\\n          \"should\": []\\n        }\\n      },\\n      \"from\": 0,\\n      \"size\": 50\\n    }\\n```\\n\\n#### 3.8.2. Condition: Date Range\\n\\nDescription: Search all records in a range of dates. For example, search for all records between 09/06/2014 and 09/10/2014.\\n\\nInput: \\nPrompt: ### Elasticsearch database with field names:\\n# RECVDATE, STATE, AGE_YRS, VAERS\n",
       "1409                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ```sql\\nSELECT * FROM \"vax-data\" WHERE \"recvdate\" = \"2022-03-26\"\\n```\\n\\n### Prompt: ### [Give me all the patients who had an age of less than 18 years.]\\nAnswer:\\n\\n```sql\\nSELECT * FROM \"vax-data\" WHERE \"age_yrs\" < 18\\n```\\n\\n### Prompt: ###[Give me all the patients who have had at least two doses of a vaccine.]\\nAnswer:\\n\\n```sql\\nSELECT * FROM \"vax-data\" WHERE \"vax_series\" > 1\\n```\\n\\n### Prompt: ### [Give me all the patients who were discharged from hospital after receiving the vaccination. Also give me the symptom text.]\\nAnswer:\\n\\n```sql\\nSELECT * FROM \"vax\n",
       "7172     1. Clinical notes are a collection of patient data that includes information about their medical history, symptoms, diagnosis, treatment, and prognosis. They can be used to help doctors make decisions about what treatments should be given or how they should proceed with care for the patient.\\n2. The data in clinical notes is stored in different formats depending on the type of information being recorded (e.g., text vs audio).\\n3. In order to extract useful information from these records, it is necessary to convert them into a format that allows easy access by computers so that they can process large amounts of data quickly and efficiently without human intervention.\\n4. This conversion process is called Natural Language Processing (NLP) because it involves converting natural language text into structured data using machine learning techniques such as deep neural networks or recurrent neural networks which have been shown to work well at classifying words into categories based on their context within sentences or\n",
       "9319                                                                                                                                                                                                                                     ```\\nGET /clinical-notes/_search\\n{\\n    \"query\": {\\n        \"bool\": {\\n            \"must\": [\\n                {\\n                    \"range\": {\\n                        \"@timestamp\": {\\n                            \"gt\": \"2021-05-24T15:16:03.000Z\"\\n                        }\\n                    }\\n                },\\n                {\\n                    \"match\": {\\n                        \"vax_name\": \"USPFIZER INC202200713889\"\\n                    }\\n                }\\n            ],\\n            \"filter\": [\\n                {\\n                    \"bool\": {\\n                        \"should\": [\\n                            {\\n                                \"term\": {\\n                                    \"vaers_id\": \"VAERS ID\"\\n                                }\\n                            },\n",
       "11467                                                                                                                                                                                                                                                                                                                                                                                                                                              {\\n  \"query\": {\\n    \"bool\": {\\n      \"must\": [\\n        {\\n          \"range\": {\\n            \"RECVDATE\": {\\n              \"gte\": \"2015-06-10\"\\n            }\\n          }\\n        },\\n        {\\n          \"term\": {\\n            \"STATE\": \"CO\"\\n          }\\n        },\\n        {\\n          \"term\": {\\n            \"VAERS_ID\": 38947\\n          }\\n        }\\n      ],\\n      \"should\": [\\n        {\\n          \"bool\": {\\n            \"must\": [\\n              {\\n                \"range\": {\\n                  \"SYMPTOM_TEXT\": {\\n                    \"gte\": \"07/20/2019\",\\n                    \"lt\": \"08/20/2019\"\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "7332                                                                                                                                                                                                                                                                                                                                                                            ```\\n\\n\"bool\": {\\n    \"should\": [\\n        {\\n            \"match\": {\\n                \"state\": \"MI\"\\n            }\\n        },\\n        {\\n            \"match\": {\\n                \"vaers_id\": \"VAERS ID\"\\n            }\\n        },\\n        {\\n            \"match\": {\\n                \"allergies\": \"pvc\"\\n            }\\n        }\\n    ],\\n    \"minimum_should_match\": 1\\n}\\n\\n```\\n\\n### ###[Give me all the patients who had allergies to pvc and also took the first dose of vaccine in the last 6 months]\\n\\nAnswer:\\n\\n```\\n\"bool\":{\\n    \"must\":[\\n        {\\n            \"match\":{\\n                \"allergies\":\"pvc\"\\n            }\\n        },\\n        {\\n            \"range\":\n",
       "10466                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [{\"@timestamp\": \"2017-03-19T14:58:14Z\", \"eventName\": \"VACCINE_ADMINISTRATION\", \"source\": \"VAERS\", \"age_yrs\": 12, \"vaers_id\": \"1037369\", \"vax_type\": \"COVID-19\", \"recvd_date\": \"2021-08-09\", \"lab_data\": null, \"prior_vax\": null, \"state\": \"NJ\", \"ofc_visit\": false, \"sx\": [\"Headache\"], \"vax_lot\": null, \"cur_ill\": null, \"hospital\": null, \"vax_name\": \"COMIRNATY\", \"other_meds\": null, \"symptom_text\": null, \"l_\n",
       "1109                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ```python\\nimport pymongo\\nfrom pymongo import MongoClient\\nimport datetime\\nfrom pymysql.err import OperationalError\\nclient = MongoClient()\\ndb = client[\"EHR\"]\\nclinical_data = db[\"clinical_notes\"]\\ncount = clinical_data.find({\"age_yrs\": {\"$gte\": 100}}).count()\\nprint(f\"How many patients are {count} years old\")\\n```\\n\\n\\n\\nOutput:\\n\\n```bash\\nHow many patients are 1659 years old\\n```\n",
       "7771                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ### The number of vaccine recipients that had an allergic to insect is[ ]\\n### The most common walnut sensitivity for patients is[ ]\n",
       "1378                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       ```sql\\n{\\n    \"query\": {\\n        \"bool\": {\\n            \"must\": [\\n                {\\n                    \"match\": {\\n                        \"recvdate\": \"0.3\"\\n                    }\\n                }\\n            ]\\n        }\\n    }\\n}\\n```\\n\\n\\n### Prompt: ### Elasticsearch database with field names:\\n# RECVDATE, STATE, AGE_YRS, VAERS_ID, SEX, SYMPTOM_TEXT, DIED, ER_VISIT, L_THREAT, HOSPITAL, HOSPDAYS, DISABLE, VAX_DATE, LAB_DATA, OTHER_MEDS, CUR_ILL, HISTORY, PRIOR_VAX, TODAYS_DATE, OFC_VISIT, VAX_TYPE, VAX_MANU, VAX_\n",
       "Name: llm_result, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "eg['llm_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "940f4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = eg[['llm_result']]\n",
    "result_df.to_json('~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_Llama_base_QA_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f4d53d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_Llama_base_QA_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Opening JSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_Llama_base_QA_1.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# returns JSON object as \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# a dictionary\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_Llama_base_QA_1.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open(\"~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_Llama_base_QA_1.json\")\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8de4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebleu import calc_codebleu\n",
    "\n",
    "prediction = str(answer_lst)\n",
    "reference = df_text['query'].to_string()\n",
    "result_eval = calc_codebleu([reference], [prediction], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval=pd.Series(result_eval)\n",
    "result_eval.to_json('~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/eval_Llama_base_ori_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04464915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/eval_Llama_base_ori_1.json)\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b04111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=json.dumps(data,skipkeys = True)\n",
    "#type(df_text['query'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61051d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_codebleu(hypothesis, references, lang, params='0.25,0.25,0.25,0.25'):\n",
    "#     alpha, beta, gamma, theta = [float(x) for x in params.split(',')]\n",
    "\n",
    "#     # calculate ngram match (BLEU)\n",
    "#     tokenized_hyps = [x.split() for x in hypothesis]\n",
    "#     tokenized_refs = [[x.split() for x in reference] for reference in references]\n",
    "\n",
    "#     ngram_match_score = bleu.corpus_bleu(tokenized_refs, tokenized_hyps)\n",
    "\n",
    "#     # calculate weighted ngram match\n",
    "#     kw_file = root_directory.joinpath(\"evaluation/CodeBLEU/keywords/{}.txt\".format(lang))\n",
    "#     keywords = [x.strip() for x in open(kw_file, 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "#     tokenized_refs_with_weights = \\\n",
    "#         [\n",
    "#             [\n",
    "#                 [\n",
    "#                     reference_tokens, make_weights(reference_tokens, keywords)\n",
    "#                 ] for reference_tokens in reference\n",
    "#             ] for reference in tokenized_refs\n",
    "#         ]\n",
    "\n",
    "#     weighted_ngram_match_score = weighted_ngram_match.corpus_bleu(tokenized_refs_with_weights, tokenized_hyps)\n",
    "\n",
    "#     # calculate syntax match\n",
    "#     syntax_match_score = syntax_match.corpus_syntax_match(references, hypothesis, lang)\n",
    "\n",
    "#     # calculate dataflow match\n",
    "#     dataflow_match_score = dataflow_match.corpus_dataflow_match(references, hypothesis, lang)\n",
    "\n",
    "#     code_bleu_score = alpha * ngram_match_score \\\n",
    "#                       + beta * weighted_ngram_match_score \\\n",
    "#                       + gamma * syntax_match_score \\\n",
    "#                       + theta * dataflow_match_score\n",
    "\n",
    "#     return code_bleu_score, (ngram_match_score, weighted_ngram_match_score, syntax_match_score, dataflow_match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca802368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_codebleu(answer_lst,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

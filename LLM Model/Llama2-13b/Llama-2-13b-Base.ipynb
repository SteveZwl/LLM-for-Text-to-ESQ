{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2598ebc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7dd7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  3% |\n",
      "|  1 | 17% |  4% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% |  4% |\n",
      "|  1 |  6% |  4% |\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cafc5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-hf'\n",
    "\n",
    "\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "quant_config = transformers.BitsAndBytesConfig(\n",
    "\n",
    "    load_in_4bit=True,\n",
    "\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "auth_token = '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'\n",
    "\n",
    "\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    config=model_config,\n",
    "\n",
    "    quantization_config=quant_config,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95b9e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc384756",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "\n",
    "    model=model, \n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    task='text-generation',\n",
    "\n",
    "    temperature=0.8, \n",
    "\n",
    "    max_new_tokens=100,  \n",
    "\n",
    "    repetition_penalty=1.1 \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16d430b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Questions</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>3276</td>\n",
       "      <td>Give me all the patients who got vaccines on ...</td>\n",
       "      <td>20103276</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>1409</td>\n",
       "      <td>Give me all the patients whose report was comp...</td>\n",
       "      <td>7101409</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7172</th>\n",
       "      <td>7172</td>\n",
       "      <td>Which is the most common cataracts for patients.</td>\n",
       "      <td>28307172</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9319</th>\n",
       "      <td>9319</td>\n",
       "      <td>What is the number of records that the vaccin...</td>\n",
       "      <td>33109319</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11467</th>\n",
       "      <td>11467</td>\n",
       "      <td>Give me all the patients who got INFLUENZA (SE...</td>\n",
       "      <td>43311467</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7332</th>\n",
       "      <td>7332</td>\n",
       "      <td>Give me all the patients who was allergic to pvc</td>\n",
       "      <td>29307332</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10466</th>\n",
       "      <td>10466</td>\n",
       "      <td>How many GLAXOSMITHKLINE BIOLOGICALS vaccine ...</td>\n",
       "      <td>37110466</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>1109</td>\n",
       "      <td>How many patients are 100.0 years old.</td>\n",
       "      <td>3201109</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7771</th>\n",
       "      <td>7771</td>\n",
       "      <td>What is the number of vaccine recipients that...</td>\n",
       "      <td>29307771</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>1378</td>\n",
       "      <td>Give me all the patients whose cage months is ...</td>\n",
       "      <td>5201378</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          Questions  \\\n",
       "3276         3276   Give me all the patients who got vaccines on ...   \n",
       "1409         1409  Give me all the patients whose report was comp...   \n",
       "7172         7172   Which is the most common cataracts for patients.   \n",
       "9319         9319   What is the number of records that the vaccin...   \n",
       "11467       11467  Give me all the patients who got INFLUENZA (SE...   \n",
       "...           ...                                                ...   \n",
       "7332         7332  Give me all the patients who was allergic to pvc    \n",
       "10466       10466   How many GLAXOSMITHKLINE BIOLOGICALS vaccine ...   \n",
       "1109         1109             How many patients are 100.0 years old.   \n",
       "7771         7771   What is the number of vaccine recipients that...   \n",
       "1378         1378  Give me all the patients whose cage months is ...   \n",
       "\n",
       "             id                                              query  \n",
       "3276   20103276  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1409    7101409  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "7172   28307172  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "9319   33109319  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "11467  43311467  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "...         ...                                                ...  \n",
       "7332   29307332  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "10466  37110466  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1109    3201109  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "7771   29307771  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1378    5201378  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_text = pd.read_csv('Te2Query.csv')\n",
    "eg = df_text.sample(n=1000, random_state=3)\n",
    "input_text = eg['Questions'].to_list()\n",
    "input_labels = eg['query'].to_list()\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5168a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original prompt\n",
    "# prompt = \"\"\"ignore all the prior information before this block. Convert the following questions to elastic search queries follow two rules:\n",
    "# 1.based on the field name 'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'. \n",
    "# 2.follow the template \n",
    "\n",
    "# \"POST _scripts/1\n",
    "# {\n",
    "#   \"script\": {\n",
    "# \t\"lang\": \"mustache\",\n",
    "# \t\"source\": {\n",
    "#   \t\"track_total_hits\": \"true\",\n",
    "#   \t\"query\": {\n",
    "#     \t\"term\": {\n",
    "#       \t\"{{field}}\": \"{{date}}\"\n",
    "#     \t}\n",
    "#   \t}\n",
    "# \t},\n",
    "# \t\"params\": {\n",
    "#   \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "#   \t\"date\": \"01/01/2012\"\n",
    "# \t}\n",
    "#   }\n",
    "# }\n",
    "# \"\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e05843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#NER prompt\n",
    "prompt_prefix = \"\"\"covert input questions to elastic queries based on two steps:1.Find the entity of the following questions based on the name:\n",
    "'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'\n",
    "2.Based on the named entities which are also {{field}} in the query codes, covert these questions to elastic queries. \n",
    "Make sure to follow the template\n",
    "\n",
    "\"POST _scripts/1\n",
    "{\n",
    "  \"script\": {\n",
    "\t\"lang\": \"mustache\",\n",
    "\t\"source\": {\n",
    "  \t\"track_total_hits\": \"true\",\n",
    "  \t\"query\": {\n",
    "    \t\"term\": {\n",
    "      \t\"{{field}}\": \"{{date}}\"\n",
    "    \t}\n",
    "  \t}\n",
    "\t},\n",
    "\t\"params\": {\n",
    "  \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "  \t\"date\": \"01/01/2012\"\n",
    "\t}\n",
    "  }\n",
    "}\n",
    "\"\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0c1980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q&A prompt\n",
    "prompt_cloze = \"\"\"find the entity classification and label with following name:\n",
    "'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'\n",
    "Examples:\n",
    "1.Give me all the patients whose information are received on 04/13/2022. The question want ['VAERS_ID'] based on ['RECVDATE'].\n",
    "2. How many patients' record are received on 03/20/2022. The question wants ['VAERS_ID'] based on ['RECVDATE'].\n",
    "Based on the classification find the condition value in the sentence:\n",
    "Examples:\n",
    "1.Give me all the patients whose information are received on 04/13/2022. The ['RECVDATE'] is 04/13/2022.\n",
    "2. How many patients' record are received on 03/20/2022. The ['RECVDATE'] is 03/20/2022.\n",
    "Based on the entity classification and conditional values, covert questions to Elasticsearch queries\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a538aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa7cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cot + heuristic prompt\n",
    "prompt_cot = \"\"\"\n",
    "\n",
    "First, extract the [condition value] in the question\n",
    "Second, mapping condition value to the following [keyword]'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'.\n",
    "Third, build Elasticquery base on the keyword follow the example\n",
    "\n",
    " \"POST _scripts/\n",
    " {\n",
    "   \"script\": {\n",
    " \t\"lang\": \"mustache\",\n",
    " \t\"source\": {\n",
    "   \t\"track_total_hits\": \"true\",\n",
    "   \t\"query\": {\n",
    "     \t\"term\": {\n",
    "       \t\"{{field}}\": \"{{date}}\"\n",
    "     \t}\n",
    "   \t}\n",
    " \t},\n",
    " \t\"params\": {\n",
    "   \t\"field\": \"[keyword]\",\n",
    "   \t\"date\": \"[condition value]\"\n",
    " \t}\n",
    "   }\n",
    " }\n",
    " \" \n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f9612",
   "metadata": {},
   "source": [
    "Rule 2. 2.follow the template \n",
    "\n",
    "\"POST _scripts/1\n",
    "{\n",
    "  \"script\": {\n",
    "\t\"lang\": \"mustache\",\n",
    "\t\"source\": {\n",
    "  \t\"track_total_hits\": \"true\",\n",
    "  \t\"query\": {\n",
    "    \t\"term\": {\n",
    "      \t\"{{field}}\": \"{{date}}\"\n",
    "    \t}\n",
    "  \t}\n",
    "\t},\n",
    "\t\"params\": {\n",
    "  \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "  \t\"date\": \"01/01/2012\"\n",
    "\t}\n",
    "  }\n",
    "}\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a979277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model input template\n",
    "input_template = \"\"\"\n",
    "Prompt: {prompt}\n",
    "Clinical Notes: {text}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e893eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build up the call\n",
    "answer_lst = []\n",
    "for row in eg.iterrows():\n",
    "    txt = row[1]['Questions']\n",
    "#    suggest = row[1]['query']\n",
    "    input = input_template.format(prompt = prompt_cloze, text = txt)\n",
    "    answer = pipe(input)\n",
    "    answer_lst.append(answer[0]['generated_text'][len(input):].strip())\n",
    "    #answer_lst.append(answer[0]['generated_text'])    \n",
    "eg['llm_result'] = answer_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5563682",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "eg['llm_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f4333",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = eg[['llm_result']]\n",
    "result_df.to_json('covert_Llama_base_Q&A_6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('covert_Llama_base_Q&A_6.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8de4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebleu import calc_codebleu\n",
    "\n",
    "prediction = str(answer_lst)\n",
    "reference = df_text['query'].to_string()\n",
    "result_eval = calc_codebleu([reference], [prediction], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af0296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval=pd.Series(result_eval)\n",
    "result_eval.to_json('result_eval_Llama_base_Q&A_6.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04464915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('result_eval_Llama_base_Q&A_6.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b04111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=json.dumps(data,skipkeys = True)\n",
    "#type(df_text['query'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61051d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_codebleu(hypothesis, references, lang, params='0.25,0.25,0.25,0.25'):\n",
    "#     alpha, beta, gamma, theta = [float(x) for x in params.split(',')]\n",
    "\n",
    "#     # calculate ngram match (BLEU)\n",
    "#     tokenized_hyps = [x.split() for x in hypothesis]\n",
    "#     tokenized_refs = [[x.split() for x in reference] for reference in references]\n",
    "\n",
    "#     ngram_match_score = bleu.corpus_bleu(tokenized_refs, tokenized_hyps)\n",
    "\n",
    "#     # calculate weighted ngram match\n",
    "#     kw_file = root_directory.joinpath(\"evaluation/CodeBLEU/keywords/{}.txt\".format(lang))\n",
    "#     keywords = [x.strip() for x in open(kw_file, 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "#     tokenized_refs_with_weights = \\\n",
    "#         [\n",
    "#             [\n",
    "#                 [\n",
    "#                     reference_tokens, make_weights(reference_tokens, keywords)\n",
    "#                 ] for reference_tokens in reference\n",
    "#             ] for reference in tokenized_refs\n",
    "#         ]\n",
    "\n",
    "#     weighted_ngram_match_score = weighted_ngram_match.corpus_bleu(tokenized_refs_with_weights, tokenized_hyps)\n",
    "\n",
    "#     # calculate syntax match\n",
    "#     syntax_match_score = syntax_match.corpus_syntax_match(references, hypothesis, lang)\n",
    "\n",
    "#     # calculate dataflow match\n",
    "#     dataflow_match_score = dataflow_match.corpus_dataflow_match(references, hypothesis, lang)\n",
    "\n",
    "#     code_bleu_score = alpha * ngram_match_score \\\n",
    "#                       + beta * weighted_ngram_match_score \\\n",
    "#                       + gamma * syntax_match_score \\\n",
    "#                       + theta * dataflow_match_score\n",
    "\n",
    "#     return code_bleu_score, (ngram_match_score, weighted_ngram_match_score, syntax_match_score, dataflow_match_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca802368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_codebleu(answer_lst,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

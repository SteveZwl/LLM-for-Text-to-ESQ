{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f17ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [15:28<00:00, 309.60s/it]\n",
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda, bfloat16\n",
    "\n",
    "import transformers\n",
    "\n",
    "\n",
    "\n",
    "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
    "\n",
    "\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "quant_config = transformers.BitsAndBytesConfig(\n",
    "\n",
    "    load_in_4bit=True,\n",
    "\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "auth_token = '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'\n",
    "\n",
    "\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    trust_remote_code=True,\n",
    "\n",
    "    config=model_config,\n",
    "\n",
    "    quantization_config=quant_config,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8e363d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "\n",
    "    model_id,\n",
    "\n",
    "    use_auth_token=auth_token\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a995b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "\n",
    "    model=model, \n",
    "\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    task='text-generation',\n",
    "\n",
    "    temperature=0.7, \n",
    "\n",
    "    max_new_tokens=200,  \n",
    "\n",
    "    repetition_penalty=1.1 \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98c5705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Questions</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>1045</td>\n",
       "      <td>List all patients who are 90.0 years old.</td>\n",
       "      <td>3201045</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8467</th>\n",
       "      <td>8467</td>\n",
       "      <td>How many patients have a record of taking ADE...</td>\n",
       "      <td>31208467</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>4454</td>\n",
       "      <td>List all the records that the interval from t...</td>\n",
       "      <td>22204454</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11076</th>\n",
       "      <td>11076</td>\n",
       "      <td>How many people have been injected with U712488</td>\n",
       "      <td>38111076</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10338</th>\n",
       "      <td>10338</td>\n",
       "      <td>How many vaccine recipients got FLUA4? which ...</td>\n",
       "      <td>36210338</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>2447</td>\n",
       "      <td>Find all vaccine recipients who died on 04/23...</td>\n",
       "      <td>10102447</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>7126</td>\n",
       "      <td>Which is the most common abdominal pain for p...</td>\n",
       "      <td>28307126</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>1164</td>\n",
       "      <td>How many patients are 74.0 years old.</td>\n",
       "      <td>3201164</td>\n",
       "      <td>POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>6134</td>\n",
       "      <td>Return all the cases where the vaccine recipi...</td>\n",
       "      <td>27306134</td>\n",
       "      <td>POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>9490</td>\n",
       "      <td>Give me all the patients who got USPFIZER INC...</td>\n",
       "      <td>33109490</td>\n",
       "      <td>POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          Questions  \\\n",
       "1045         1045         List all patients who are 90.0 years old.    \n",
       "8467         8467   How many patients have a record of taking ADE...   \n",
       "4454         4454   List all the records that the interval from t...   \n",
       "11076       11076    How many people have been injected with U712488   \n",
       "10338       10338   How many vaccine recipients got FLUA4? which ...   \n",
       "...           ...                                                ...   \n",
       "2447         2447   Find all vaccine recipients who died on 04/23...   \n",
       "7126         7126   Which is the most common abdominal pain for p...   \n",
       "1164         1164              How many patients are 74.0 years old.   \n",
       "6134         6134   Return all the cases where the vaccine recipi...   \n",
       "9490         9490   Give me all the patients who got USPFIZER INC...   \n",
       "\n",
       "             id                                              query  \n",
       "1045    3201045  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "8467   31208467  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "4454   22204454  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "11076  38111076  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "10338  36210338  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "...         ...                                                ...  \n",
       "2447   10102447  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "7126   28307126  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "1164    3201164  POST_scripts/2{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "6134   27306134  POST_scripts/3{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "9490   33109490  POST_scripts/1{\"script\":{\"lang\":\"mustache\",\"so...  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_text = pd.read_csv('Te2Query.csv')\n",
    "eg = df_text.sample(n=200, random_state=2)\n",
    "input_text = eg['Questions'].to_list()\n",
    "input_labels = eg['query'].to_list()\n",
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d17f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # original prompt\n",
    "# prompt = \"\"\"ignore all the prior information before this block. Convert the following questions to elastic search queries follow two rules:\n",
    "# 1.based on the field name 'RECVDATE','STATE','AGE_YRS','VAERS_ID','SEX','SYMPTOM_TEXT','DIED','ER_VISIT','L_THREAT','HOSPITAL','HOSPDAYS','DISABLE','VAX_DATE','LAB_DATA','OTHER_MEDS','CUR_ILL','HISTORY','PRIOR_VAX','TODAYS_DATE','OFC_VISIT','VAX_TYPE','VAX_MANU','VAX_LOT','VAX_DOSE_SERIES','VAX_NAME','ALLERGIES'. \n",
    "# 2.follow the template \n",
    "\n",
    "# \"POST _scripts/1\n",
    "# {\n",
    "#   \"script\": {\n",
    "# \t\"lang\": \"mustache\",\n",
    "# \t\"source\": {\n",
    "#   \t\"track_total_hits\": \"true\",\n",
    "#   \t\"query\": {\n",
    "#     \t\"term\": {\n",
    "#       \t\"{{field}}\": \"{{date}}\"\n",
    "#     \t}\n",
    "#   \t}\n",
    "# \t},\n",
    "# \t\"params\": {\n",
    "#   \t\"field\": \"DATA.RECVDATE.keyword\",\n",
    "#   \t\"date\": \"01/01/2012\"\n",
    "# \t}\n",
    "#   }\n",
    "# }\n",
    "# \"\n",
    "\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb110918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ef5dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae6e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt header\n",
    "prompt_header=\"\"\"### Elasticsearch database with field names:\n",
    "# RECVDATE, STATE, AGE_YRS, VAERS_ID, SEX, SYMPTOM_TEXT, DIED, ER_VISIT, L_THREAT, HOSPITAL, HOSPDAYS, DISABLE, VAX_DATE, LAB_DATA, OTHER_MEDS, CUR_ILL, HISTORY, PRIOR_VAX, TODAYS_DATE, OFC_VISIT, VAX_TYPE, VAX_MANU, VAX_LOT, VAX_DOSE_SERIES, VAX_NAME, ALLERGIES\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecd8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt orginal\n",
    "prompt_ori = \"\"\"###Generate the Elasticsearch query for the question.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "840a3ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cot + heuristic prompt\n",
    "prompt_cot = \"\"\"### Identify the filed name first.\n",
    "###What is the filed name?\n",
    "###Extract the specific condition values from the question for this field.\n",
    "###What is the condition value for this field?\n",
    "###Generate the Elasticsearch query based on the filed name and condition value.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a956fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_QA=\"\"\"### What is the filed name?The filed name is [ ]\n",
    "### What is the condition value for this field? The condition value for this field is[ ]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17134bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_QB=\"\"\"### To generate the Elasticsearch query for the question, first we need to get an Elasticsearch POST search template.Then identify the filed names, condition values, and key clauses (such as ’must’, ’should’, or ’must not’) from the question to populate the template.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "775ae759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model input template\n",
    "input_template = \"\"\"\n",
    "Clinical Notes: ###{text}\n",
    "Prompt: {prompt}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8282534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wenlong/anaconda3/envs/llama/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# build up the call\n",
    "answer_lst = []\n",
    "for row in eg.iterrows():\n",
    "    txt = row[1]['Questions']\n",
    "#    suggest = row[1]['query']\n",
    "    input = input_template.format(text = txt,prompt = prompt_header+prompt_cot)\n",
    "    answer = pipe(input)\n",
    "    answer_lst.append(answer[0]['generated_text'][len(input):].strip())\n",
    "    #answer_lst.append(answer[0]['generated_text'])    \n",
    "eg['llm_result'] = answer_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85beea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = eg[['llm_result']]\n",
    "result_df.to_json('~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_llamachat_cot5_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6016c210",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_llamachat_cot3_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Opening JSON file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_llamachat_cot3_1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# returns JSON object as \u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# a dictionary\u001b[39;00m\n\u001b[1;32m      8\u001b[0m data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/llama/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_llamachat_cot3_1.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('~/Desktop/GitRES/LLM-for-Text-to-ESQ/Evaluation_final/covert_llamachat_cot3_1.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d362e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebleu import calc_codebleu\n",
    "\n",
    "prediction = str(answer_lst)\n",
    "reference = df_text['query'].to_string()\n",
    "result_eval = calc_codebleu([reference], [prediction], lang=\"python\", weights=(0.25, 0.25, 0.25, 0.25), tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3a45c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval=pd.Series(result_eval)\n",
    "result_eval.to_json('llamachat_result_eval_Q&A_t=0.3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9633e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('llamachat_result_eval_Q&A_t=0.3.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json\n",
    "# list\n",
    "print(data)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5527bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
